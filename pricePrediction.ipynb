{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "pricePrediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmUp0t7Q_hOj",
        "colab_type": "text"
      },
      "source": [
        "# 개발 노트\n",
        "make_BuyHoldSell_point 고려할게 많다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PXRpEypCqwnS"
      },
      "source": [
        "# **Bitcoin Buy, Hold, Sell decision making project**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zhg84Ze3q065",
        "outputId": "9bf89c24-890c-43cf-a794-1f15a0ac262d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ukQCcKKIqwnT",
        "outputId": "b00f6352-c322-47e7-e1aa-1ef291c0a9a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Activation, Lambda\n",
        "from keras import optimizers\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KoTh8kz-qwnW"
      },
      "source": [
        "**X : 시가,고가, 저가, 종가, 누적거래금액, 누적거래량**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NU1EMaJRqwnX",
        "colab": {}
      },
      "source": [
        "rawData = np.loadtxt(\"/content/drive/My Drive/Colab Notebooks/priceData_1min.csv\", delimiter=',')\n",
        "#rawData = np.loadtxt(\"priceData.csv\", delimiter=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "47TmwC-2qwnZ",
        "colab": {}
      },
      "source": [
        "X = rawData[:, 1:]\n",
        "Y = np.zeros((len(X), 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aFiFX-6kqwnb"
      },
      "source": [
        "### Normalization and Standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nCyKTSSvqwnc",
        "colab": {}
      },
      "source": [
        "def normalize(data):\n",
        "    return (data - np.min(data, axis = 0))/(np.max(data, axis = 0) - np.min(data, axis = 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lKZIF9xsqwne",
        "colab": {}
      },
      "source": [
        "def standardize(data) :\n",
        "    return (data - np.mean(data, axis = 0))/np.std(data, axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v7dVEBRIqwng",
        "colab": {}
      },
      "source": [
        "X = normalize(X)\n",
        "X = standardize(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dRNCx1z2qwnh"
      },
      "source": [
        "## Functions\n",
        "---\n",
        "make_BuyHoldSell_point()<br/>print_BuyHoldSell_point()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I2VWHbK3qwni"
      },
      "source": [
        "### make_BuyHoldSell_point\n",
        "This function makes Buy, Hold, Sell point. (Y)\n",
        "np.ndarray Y.shape is (len(X), 3)\n",
        "- Buy : Y[ , 0] = 1\n",
        "- Hold : Y[ , 1] = 1\n",
        "- Sell : Y[ , 2] = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h31MSUCYqwnj",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Variable for make_BuyHoldSell_point\n",
        "'''\n",
        "candle_time = 1 # 1분봉\n",
        "period = 60/1*12 #72 # (60분 / 10분봉) * 12시간\n",
        "period = (int)(period/2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b_PcN2aCqwnl",
        "colab": {}
      },
      "source": [
        "make_point_length = 30 // candle_time # 최저, 최고점에서 몇분까지 Buy, Sell Point로 결정할지 정하는 변수\n",
        "about_commision = 3 * 60 // candle_time # 수수료 발생을 고려하여, Buy, Sell Point가 3시간 이내일 경우 Buy, Sell Point를 Hold함\n",
        "def make_BuyHoldSell_point(X, Y) :\n",
        "    \n",
        "    Y[:, :] = 0\n",
        "        \n",
        "    for i in range(period, len(X)-period) :\n",
        "\n",
        "        arr = X[i-period:i+period, 3]\n",
        "\n",
        "        minIndex = np.argmin(arr)\n",
        "        maxIndex = np.argmax(arr)\n",
        "        \n",
        "        if abs(maxIndex - minIndex) > about_commision :\n",
        "            for j in range(make_point_length) :\n",
        "                if i-period + maxIndex + j < len(X) and i-period + minIndex + j < len(X) :\n",
        "                    if Y[i-period + minIndex + j, 2] == 0 :\n",
        "                        Y[i-period + minIndex + j, 0] = 1\n",
        "                    if Y[i-period + maxIndex + j, 0] == 0 :\n",
        "                        Y[i-period + maxIndex + j, 2] = 1\n",
        "        \n",
        "    for i in range(0, len(X)) :\n",
        "        if Y[i, 0] == 0 and Y[i, 2] == 0 :\n",
        "            Y[i, 1] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zQau0VOXqwno"
      },
      "source": [
        "### print_BuyHoldSell_point\n",
        "This function shows time, BuyHoldSell, price."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "44lDUiL7qwnp",
        "colab": {}
      },
      "source": [
        "def print_BuyHoldSell_point(X, Y) :\n",
        "    for i in range(0, len(X)) :\n",
        "        if Y[i, 0] == 1 :\n",
        "            print(i, \"\\tBuy\\t\", X[i, 3], Y[i])\n",
        "        elif Y[i, 2] == 1 :\n",
        "            print(i, \"\\tSell\\t\", X[i, 3], Y[i])\n",
        "        else :\n",
        "            print(i, \"\\tHold\\t\", X[i, 3], Y[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3K-Grp5eqwnr"
      },
      "source": [
        "## Building an RNN with LSTM\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iHT4ig0sqwns",
        "colab": {}
      },
      "source": [
        "make_BuyHoldSell_point(X, Y)\n",
        "#print_BuyHoldSell_point(X, Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47oYXgUy_hO_",
        "colab_type": "code",
        "outputId": "a4df5a3e-de77-4e3b-ef27-e14c1c5254fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(len(X))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1010600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yvs5r3Vdqwnv",
        "colab": {}
      },
      "source": [
        "train_number = (int)(len(X) * 0.9)\n",
        "\n",
        "X_train, X_test = X[:train_number], X[train_number:]\n",
        "Y_train, Y_test = Y[:train_number], Y[train_number:]\n",
        "\n",
        "#X_train = X_train.reshape((1, X_train.shape[0], X_train.shape[1]))\n",
        "#X_test = X_test.reshape((1, X_test.shape[0], X_test.shape[1]))\n",
        "#Y_train = Y_train.reshape((1, Y_train.shape[0], Y_train.shape[1]))\n",
        "#Y_test = Y_test.reshape((1, Y_test.shape[0], Y_test.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bKB3iwO8qwnx",
        "outputId": "ef276542-8346-4005-908d-1ec8210b30fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(909540, 6)\n",
            "(909540, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L35d3GPsqwnz"
      },
      "source": [
        "### Setting the RNN Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CnlPc3Djqwnz",
        "colab": {}
      },
      "source": [
        "batch_size = (int)(909540/1000)            # Batch size (you may try different values)\n",
        "batch_length = (int)(train_number/1000)  # 9106\n",
        "epochs = 15               # Epoch (you may try different values)\n",
        "seq_len = 60 * 24 * 3     # 432 sequence data (Representing the last 3 days)\n",
        "loss='mean_squared_error' # Since the metric is MSE/RMSE\n",
        "opt = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01) #imizer = 'rmsprop'     # Recommended optimizer for RNN\n",
        "activation = 'relu'       # Linear activation\n",
        "input_shape=(None,6)      # Input dimension\n",
        "output_dim = 32           # Output dimension"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a6p_o3rVqwn1"
      },
      "source": [
        "### Creating a Sequential Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kjIBsaG5qwn2",
        "outputId": "0bb57311-2a22-444a-f1a0-e3b30b7ba8a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(units=output_dim, return_sequences=True, input_shape=input_shape))\n",
        "model.add(Dense(units=output_dim,activation=activation))\n",
        "model.add(LSTM(units=output_dim, return_sequences=False))\n",
        "model.add(Dense(units=3,activation='softmax'))\n",
        "model.compile(optimizer=opt,loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T7zOTsQdqwn3"
      },
      "source": [
        "### Training the RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JWya_msdqwn4",
        "outputId": "8fc7f0fb-57fe-4890-cbbc-0bc121e0d3b1",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, None, 32)          4992      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, None, 32)          1056      \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 14,467\n",
            "Trainable params: 14,467\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gXYVkyH_hPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainning_Model(X_train, Y_train, batch_length, batch_size) :\n",
        "    \n",
        "    '''\n",
        "    Make empty buy_list_number, hold_list_number, sell_list_number '''\n",
        "    buy_list_number, hold_list_number, sell_list_number = [], [], []\n",
        "    \n",
        "    for i in range(seq_len, train_number) :\n",
        "        if Y_train[i, 0] == 1 :\n",
        "            buy_list_number.append(i)\n",
        "        elif Y_train[i, 1] == 1 :\n",
        "            hold_list_number.append(i)\n",
        "        elif Y_train[i, 2] == 1 :\n",
        "            sell_list_number.append(i)\n",
        "    \n",
        "    buy_list_number = np.array(buy_list_number)\n",
        "    hold_list_number = np.array(hold_list_number)\n",
        "    sell_list_number = np.array(sell_list_number)\n",
        "    \n",
        "    ''''''\n",
        "    train_order_number = np.hstack((buy_list_number, hold_list_number, sell_list_number))\n",
        "    np.random.shuffle(train_order_number)\n",
        "    \n",
        "    ''''''\n",
        "    for epoch in range(epochs) :\n",
        "    \n",
        "        for batch in range(math.ceil(len(X_train)/batch_length)) :\n",
        "          \n",
        "            print(\"Epoch : %d / %d\"%(epoch, epochs), \"\\tBatch : %d / %d\"%(batch, math.ceil(len(X_train)/batch_length)), \"\\t\")\n",
        "          \n",
        "            inputData = np.zeros((0, seq_len, 6))    # (m, seq_len, 6)\n",
        "            outputData = np.zeros((0, 3))    # (m, seq_len, 6)\n",
        "            \n",
        "            for i in range(batch_length) :\n",
        "              \n",
        "                if i%100 == 0 :\n",
        "                    print(i, end = ',')\n",
        "                    \n",
        "                if batch*batch_length + i < len(train_order_number) :\n",
        "                    target_array_number = train_order_number[batch*batch_length + i]\n",
        "                    X_input = X_train[target_array_number - seq_len : target_array_number, :]\n",
        "                else :\n",
        "                    X_input = X_train[target_array_number - seq_len :, :]\n",
        "\n",
        "                X_input = X_input.reshape((1, X_input.shape[0], X_input.shape[1]))\n",
        "                \n",
        "                #print(\"X, Y, input, output :\", X_input.shape, Y_train[target_array_number, :].shape, inputData.shape, outputData.shape)\n",
        "                inputData = np.append(inputData, X_input, axis = 0)\n",
        "                outputData = np.append(outputData, Y_train[target_array_number, :].reshape((1, 3)), axis = 0)\n",
        "\n",
        "            model.fit(x=inputData, y=outputData, epochs=1, validation_split=0.00, batch_size = batch_size)\n",
        "        \n",
        "    model.save('predict_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPG9fxN8_hPX",
        "colab_type": "code",
        "outputId": "c81d5b7e-9c1f-4a34-90a8-f09e39c043d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trainning_Model(X_train, Y_train, batch_length, batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0 / 15 \tBatch : 0 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8560\n",
            "Epoch : 0 / 15 \tBatch : 1 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 1.0045\n",
            "Epoch : 0 / 15 \tBatch : 2 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.9131\n",
            "Epoch : 0 / 15 \tBatch : 3 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8546\n",
            "Epoch : 0 / 15 \tBatch : 4 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 0.8867\n",
            "Epoch : 0 / 15 \tBatch : 5 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8799\n",
            "Epoch : 0 / 15 \tBatch : 6 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.9034\n",
            "Epoch : 0 / 15 \tBatch : 7 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8916\n",
            "Epoch : 0 / 15 \tBatch : 8 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8908\n",
            "Epoch : 0 / 15 \tBatch : 9 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8974\n",
            "Epoch : 0 / 15 \tBatch : 10 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8699\n",
            "Epoch : 0 / 15 \tBatch : 11 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8902\n",
            "Epoch : 0 / 15 \tBatch : 12 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.9067\n",
            "Epoch : 0 / 15 \tBatch : 13 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.9119\n",
            "Epoch : 0 / 15 \tBatch : 14 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 0.8609\n",
            "Epoch : 0 / 15 \tBatch : 15 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8552\n",
            "Epoch : 0 / 15 \tBatch : 16 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8784\n",
            "Epoch : 0 / 15 \tBatch : 17 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8672\n",
            "Epoch : 0 / 15 \tBatch : 18 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8926\n",
            "Epoch : 0 / 15 \tBatch : 19 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8654\n",
            "Epoch : 0 / 15 \tBatch : 20 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8287\n",
            "Epoch : 0 / 15 \tBatch : 21 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8509\n",
            "Epoch : 0 / 15 \tBatch : 22 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8489\n",
            "Epoch : 0 / 15 \tBatch : 23 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8830\n",
            "Epoch : 0 / 15 \tBatch : 24 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8653\n",
            "Epoch : 0 / 15 \tBatch : 25 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8759\n",
            "Epoch : 0 / 15 \tBatch : 26 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8898\n",
            "Epoch : 0 / 15 \tBatch : 27 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8755\n",
            "Epoch : 0 / 15 \tBatch : 28 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8681\n",
            "Epoch : 0 / 15 \tBatch : 29 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8701\n",
            "Epoch : 0 / 15 \tBatch : 30 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8758\n",
            "Epoch : 0 / 15 \tBatch : 31 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8655\n",
            "Epoch : 0 / 15 \tBatch : 32 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8762\n",
            "Epoch : 0 / 15 \tBatch : 33 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 17ms/step - loss: 0.8979\n",
            "Epoch : 0 / 15 \tBatch : 34 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 17ms/step - loss: 0.8380\n",
            "Epoch : 0 / 15 \tBatch : 35 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8911\n",
            "Epoch : 0 / 15 \tBatch : 36 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8498\n",
            "Epoch : 0 / 15 \tBatch : 37 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8771\n",
            "Epoch : 0 / 15 \tBatch : 38 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8717\n",
            "Epoch : 0 / 15 \tBatch : 39 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8823\n",
            "Epoch : 0 / 15 \tBatch : 40 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8564\n",
            "Epoch : 0 / 15 \tBatch : 41 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8874\n",
            "Epoch : 0 / 15 \tBatch : 42 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8669\n",
            "Epoch : 0 / 15 \tBatch : 43 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8712\n",
            "Epoch : 0 / 15 \tBatch : 44 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8974\n",
            "Epoch : 0 / 15 \tBatch : 45 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8841\n",
            "Epoch : 0 / 15 \tBatch : 46 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8623\n",
            "Epoch : 0 / 15 \tBatch : 47 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8412\n",
            "Epoch : 0 / 15 \tBatch : 48 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8542\n",
            "Epoch : 0 / 15 \tBatch : 49 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8534\n",
            "Epoch : 0 / 15 \tBatch : 50 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8707\n",
            "Epoch : 0 / 15 \tBatch : 51 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8350\n",
            "Epoch : 0 / 15 \tBatch : 52 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8330\n",
            "Epoch : 0 / 15 \tBatch : 53 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8285\n",
            "Epoch : 0 / 15 \tBatch : 54 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8533\n",
            "Epoch : 0 / 15 \tBatch : 55 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8816\n",
            "Epoch : 0 / 15 \tBatch : 56 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8256\n",
            "Epoch : 0 / 15 \tBatch : 57 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8669\n",
            "Epoch : 0 / 15 \tBatch : 58 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8813\n",
            "Epoch : 0 / 15 \tBatch : 59 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8282\n",
            "Epoch : 0 / 15 \tBatch : 60 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8364\n",
            "Epoch : 0 / 15 \tBatch : 61 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8324\n",
            "Epoch : 0 / 15 \tBatch : 62 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8766\n",
            "Epoch : 0 / 15 \tBatch : 63 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8601\n",
            "Epoch : 0 / 15 \tBatch : 64 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8854\n",
            "Epoch : 0 / 15 \tBatch : 65 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8556\n",
            "Epoch : 0 / 15 \tBatch : 66 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8668\n",
            "Epoch : 0 / 15 \tBatch : 67 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8426\n",
            "Epoch : 0 / 15 \tBatch : 68 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 17ms/step - loss: 0.8393\n",
            "Epoch : 0 / 15 \tBatch : 69 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8233\n",
            "Epoch : 0 / 15 \tBatch : 70 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8450\n",
            "Epoch : 0 / 15 \tBatch : 71 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8583\n",
            "Epoch : 0 / 15 \tBatch : 72 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8576\n",
            "Epoch : 0 / 15 \tBatch : 73 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8876\n",
            "Epoch : 0 / 15 \tBatch : 74 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8861\n",
            "Epoch : 0 / 15 \tBatch : 75 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 17ms/step - loss: 0.8763\n",
            "Epoch : 0 / 15 \tBatch : 76 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8764\n",
            "Epoch : 0 / 15 \tBatch : 77 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8816\n",
            "Epoch : 0 / 15 \tBatch : 78 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8824\n",
            "Epoch : 0 / 15 \tBatch : 79 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8541\n",
            "Epoch : 0 / 15 \tBatch : 80 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8667\n",
            "Epoch : 0 / 15 \tBatch : 81 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 17ms/step - loss: 0.8605\n",
            "Epoch : 0 / 15 \tBatch : 82 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8625\n",
            "Epoch : 0 / 15 \tBatch : 83 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8597\n",
            "Epoch : 0 / 15 \tBatch : 84 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8594\n",
            "Epoch : 0 / 15 \tBatch : 85 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8282\n",
            "Epoch : 0 / 15 \tBatch : 86 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8656\n",
            "Epoch : 0 / 15 \tBatch : 87 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8602\n",
            "Epoch : 0 / 15 \tBatch : 88 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8717\n",
            "Epoch : 0 / 15 \tBatch : 89 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8415\n",
            "Epoch : 0 / 15 \tBatch : 90 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 0.8565\n",
            "Epoch : 0 / 15 \tBatch : 91 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8197\n",
            "Epoch : 0 / 15 \tBatch : 92 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8644\n",
            "Epoch : 0 / 15 \tBatch : 93 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8459\n",
            "Epoch : 0 / 15 \tBatch : 94 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8207\n",
            "Epoch : 0 / 15 \tBatch : 95 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 18s 20ms/step - loss: 0.8658\n",
            "Epoch : 0 / 15 \tBatch : 96 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8571\n",
            "Epoch : 0 / 15 \tBatch : 97 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8651\n",
            "Epoch : 0 / 15 \tBatch : 98 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8308\n",
            "Epoch : 0 / 15 \tBatch : 99 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8445\n",
            "Epoch : 0 / 15 \tBatch : 100 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 23s 25ms/step - loss: 0.8468\n",
            "Epoch : 0 / 15 \tBatch : 101 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8695\n",
            "Epoch : 0 / 15 \tBatch : 102 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8295\n",
            "Epoch : 0 / 15 \tBatch : 103 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8080\n",
            "Epoch : 0 / 15 \tBatch : 104 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 17ms/step - loss: 0.8725\n",
            "Epoch : 0 / 15 \tBatch : 105 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 17ms/step - loss: 0.8693\n",
            "Epoch : 0 / 15 \tBatch : 106 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8757\n",
            "Epoch : 0 / 15 \tBatch : 107 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 17ms/step - loss: 0.8661\n",
            "Epoch : 0 / 15 \tBatch : 108 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 17ms/step - loss: 0.8105\n",
            "Epoch : 0 / 15 \tBatch : 109 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 17ms/step - loss: 0.8347\n",
            "Epoch : 0 / 15 \tBatch : 110 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8503\n",
            "Epoch : 0 / 15 \tBatch : 111 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8313\n",
            "Epoch : 0 / 15 \tBatch : 112 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 17ms/step - loss: 0.8507\n",
            "Epoch : 0 / 15 \tBatch : 113 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 23s 25ms/step - loss: 0.8487\n",
            "Epoch : 0 / 15 \tBatch : 114 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 18ms/step - loss: 0.8232\n",
            "Epoch : 0 / 15 \tBatch : 115 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 17ms/step - loss: 0.8829\n",
            "Epoch : 0 / 15 \tBatch : 116 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8263\n",
            "Epoch : 0 / 15 \tBatch : 117 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8491\n",
            "Epoch : 0 / 15 \tBatch : 118 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8835\n",
            "Epoch : 0 / 15 \tBatch : 119 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8974\n",
            "Epoch : 0 / 15 \tBatch : 120 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8951\n",
            "Epoch : 0 / 15 \tBatch : 121 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8866\n",
            "Epoch : 0 / 15 \tBatch : 122 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8442\n",
            "Epoch : 0 / 15 \tBatch : 123 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8814\n",
            "Epoch : 0 / 15 \tBatch : 124 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.9118\n",
            "Epoch : 0 / 15 \tBatch : 125 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8282\n",
            "Epoch : 0 / 15 \tBatch : 126 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8651\n",
            "Epoch : 0 / 15 \tBatch : 127 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 17ms/step - loss: 0.8853\n",
            "Epoch : 0 / 15 \tBatch : 128 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8562\n",
            "Epoch : 0 / 15 \tBatch : 129 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8439\n",
            "Epoch : 0 / 15 \tBatch : 130 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8621\n",
            "Epoch : 0 / 15 \tBatch : 131 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 17ms/step - loss: 0.8504\n",
            "Epoch : 0 / 15 \tBatch : 132 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 17ms/step - loss: 0.8375\n",
            "Epoch : 0 / 15 \tBatch : 133 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 18ms/step - loss: 0.8939\n",
            "Epoch : 0 / 15 \tBatch : 134 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 18ms/step - loss: 0.8247\n",
            "Epoch : 0 / 15 \tBatch : 135 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 17ms/step - loss: 0.8272\n",
            "Epoch : 0 / 15 \tBatch : 136 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8786\n",
            "Epoch : 0 / 15 \tBatch : 137 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8604\n",
            "Epoch : 0 / 15 \tBatch : 138 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8420\n",
            "Epoch : 0 / 15 \tBatch : 139 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8931\n",
            "Epoch : 0 / 15 \tBatch : 140 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8603\n",
            "Epoch : 0 / 15 \tBatch : 141 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 17ms/step - loss: 0.8509\n",
            "Epoch : 0 / 15 \tBatch : 142 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8772\n",
            "Epoch : 0 / 15 \tBatch : 143 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 16s 17ms/step - loss: 0.8854\n",
            "Epoch : 0 / 15 \tBatch : 144 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8552\n",
            "Epoch : 0 / 15 \tBatch : 145 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8915\n",
            "Epoch : 0 / 15 \tBatch : 146 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8528\n",
            "Epoch : 0 / 15 \tBatch : 147 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8551\n",
            "Epoch : 0 / 15 \tBatch : 148 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8495\n",
            "Epoch : 0 / 15 \tBatch : 149 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8720\n",
            "Epoch : 0 / 15 \tBatch : 150 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8579\n",
            "Epoch : 0 / 15 \tBatch : 151 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8120\n",
            "Epoch : 0 / 15 \tBatch : 152 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 18s 20ms/step - loss: 0.8514\n",
            "Epoch : 0 / 15 \tBatch : 153 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8648\n",
            "Epoch : 0 / 15 \tBatch : 154 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 22s 24ms/step - loss: 0.8422\n",
            "Epoch : 0 / 15 \tBatch : 155 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8718\n",
            "Epoch : 0 / 15 \tBatch : 156 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8500\n",
            "Epoch : 0 / 15 \tBatch : 157 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8479\n",
            "Epoch : 0 / 15 \tBatch : 158 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8604\n",
            "Epoch : 0 / 15 \tBatch : 159 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8785\n",
            "Epoch : 0 / 15 \tBatch : 160 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8356\n",
            "Epoch : 0 / 15 \tBatch : 161 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8657\n",
            "Epoch : 0 / 15 \tBatch : 162 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8497\n",
            "Epoch : 0 / 15 \tBatch : 163 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8224\n",
            "Epoch : 0 / 15 \tBatch : 164 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8480\n",
            "Epoch : 0 / 15 \tBatch : 165 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 14s 16ms/step - loss: 0.8371\n",
            "Epoch : 0 / 15 \tBatch : 166 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8781\n",
            "Epoch : 0 / 15 \tBatch : 167 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8380\n",
            "Epoch : 0 / 15 \tBatch : 168 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8544\n",
            "Epoch : 0 / 15 \tBatch : 169 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8466\n",
            "Epoch : 0 / 15 \tBatch : 170 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8127\n",
            "Epoch : 0 / 15 \tBatch : 171 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8730\n",
            "Epoch : 0 / 15 \tBatch : 172 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8777\n",
            "Epoch : 0 / 15 \tBatch : 173 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8543\n",
            "Epoch : 0 / 15 \tBatch : 174 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8879\n",
            "Epoch : 0 / 15 \tBatch : 175 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8148\n",
            "Epoch : 0 / 15 \tBatch : 176 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8302\n",
            "Epoch : 0 / 15 \tBatch : 177 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8728\n",
            "Epoch : 0 / 15 \tBatch : 178 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 20s 22ms/step - loss: 0.8423\n",
            "Epoch : 0 / 15 \tBatch : 179 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8274\n",
            "Epoch : 0 / 15 \tBatch : 180 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8656\n",
            "Epoch : 0 / 15 \tBatch : 181 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8565\n",
            "Epoch : 0 / 15 \tBatch : 182 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8490\n",
            "Epoch : 0 / 15 \tBatch : 183 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8650\n",
            "Epoch : 0 / 15 \tBatch : 184 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8505\n",
            "Epoch : 0 / 15 \tBatch : 185 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8637\n",
            "Epoch : 0 / 15 \tBatch : 186 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8833\n",
            "Epoch : 0 / 15 \tBatch : 187 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 16ms/step - loss: 0.8361\n",
            "Epoch : 0 / 15 \tBatch : 188 / 1001 \t\n",
            "0,100,200,300,400,500,600,700,800,900,Epoch 1/1\n",
            "909/909 [==============================] - 15s 17ms/step - loss: 0.8642\n",
            "Epoch : 0 / 15 \tBatch : 189 / 1001 \t\n",
            "0,100,"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jl6PxkVYqwn_"
      },
      "source": [
        "### Notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wG9sufr6qwoA",
        "colab": {}
      },
      "source": [
        "print_BuyHoldSell_point(X, Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQKxSw_I_hPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}